{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Structured Query Language, or SQL</b>, is the programming language used with databases, and it is an important skill for any data scientist. In this course, you'll build your SQL skills using <b>BigQuery</b>, a web service that lets you apply SQL to huge datasets.\n",
    "\n",
    "In this lesson, you'll learn the <em>basics of accessing and examining BigQuery datasets</em>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bigquery\n",
      "  Using cached https://files.pythonhosted.org/packages/63/83/3976eb0d7a1d665f09ab7a818d6c640f0a135df1dc854a3575d9e21cf745/bigquery-0.0.37.tar.gz\n",
      "Collecting dbstream>=0.1.19 (from bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/07/17/0d5706a6fe30060869d2b6a348d394447b02c413dfe4f890154c403743ae/dbstream-0.1.21.tar.gz\n",
      "Collecting google-cloud-bigquery>=2.4.0 (from bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/6a/d0ef792288f2fa2cfea80899a82de302b3332dfda41984fe114e2cfbf700/google_cloud_bigquery-3.11.4-py2.py3-none-any.whl\n",
      "Collecting googleauthentication>=0.0.12 (from bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/4d/6336ea00152532a1ebb194094af8b02a98be05ad7bd9a1e97a21490c442c/googleauthentication-0.0.17.tar.gz\n",
      "Collecting google-cloud-bigquery-storage>=2.1.0 (from bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/83/eb/e5016412a9c6ac26b46480f83d58112b99b48c0e38ae040b46f8795dea6f/google_cloud_bigquery_storage-2.22.0-py2.py3-none-any.whl\n",
      "Collecting pandas==1.3.4 (from bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/58/58/b729eda34f78060e14cb430c91d4f7ba3cf1e34797976877a3a1125ea5b2/pandas-1.3.4.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyarrow>=2.0.0 (from bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/68/d3410e975bebbf5be00c1238d0418345d8ec5d88b7a6c102211a1c967edd/pyarrow-12.0.1.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dacktool>=0.0.7 (from dbstream>=0.1.19->bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/ef/15/599732a77d96a3aaf13925de1d8b535bebfc424562da5d1fa4223ad51412/dacktool-0.0.7.tar.gz\n",
      "Collecting requests>=2.22.0 (from dbstream>=0.1.19->bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting google-api-core>=2.3.2 (from dbstream>=0.1.19->bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/6e/c4/c3cd048b6cbeba8d9ae50dd7643ac065b85237338aa7501b0efae91eb4d9/google_api_core-2.11.1-py3-none-any.whl\n",
      "Collecting proto-plus<2.0.0dev,>=1.15.0 (from google-cloud-bigquery>=2.4.0->bigquery)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/5b/e02636d221917d6fa2a61289b3f16002eb4c93d51c0191ac8e896d527182/proto_plus-1.22.3-py3-none-any.whl (48kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 447kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging>=20.0.0 (from google-cloud-bigquery>=2.4.0->bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/ab/c3/57f0601a2d4fe15de7a553c00adbc901425661bf048f2a22dfc500caf121/packaging-23.1-py3-none-any.whl\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-bigquery>=2.4.0->bigquery)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/8a/e9c6b48b8f4651df1b1a9d46fe94a74ed99881141b4660aa855a798c7c53/protobuf-4.24.3-py3-none-any.whl (175kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 943kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0dev,>=1.47.0 (from google-cloud-bigquery>=2.4.0->bigquery)\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/a2/781bae6df87dfd31115b24b1fe01213ef29caf9dbd0b8c1688c59aebf617/grpcio-1.58.0.tar.gz\n",
      "\u001b[31m    ERROR: Complete output from command python setup.py egg_info:\u001b[0m\n",
      "\u001b[31m    ERROR: Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-4aq_h643/grpcio/setup.py\", line 292, in <module>\n",
      "        if check_linker_need_libatomic():\n",
      "      File \"/tmp/pip-install-4aq_h643/grpcio/setup.py\", line 230, in check_linker_need_libatomic\n",
      "        stderr=PIPE,\n",
      "      File \"/snap/jupyter/6/lib/python3.7/subprocess.py\", line 775, in __init__\n",
      "        restore_signals, start_new_session)\n",
      "      File \"/snap/jupyter/6/lib/python3.7/subprocess.py\", line 1522, in _execute_child\n",
      "        raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'c++': 'c++'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-install-4aq_h643/grpcio/\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1<sup>st</sup> Big Query commands</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-63a077557d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To use BigQuery, we'll import the Python package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# To use BigQuery, we'll import the Python package\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in the workflow is to <b>create a Client object</b>. This Client object will play a central role in retrieving information from BigQuery datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data describing crime in the city of Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up feedack system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.sql.ex1 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next cell coed to fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"chicago_crime\" dataset\n",
    "dataset_ref = client.dataset(\"chicago_crime\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count tables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the tables in the \"chicago_crime\" dataset\n",
    "# Use the list_tables() method to get a list of the tables in the dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print number of tables in the dataset\n",
    "print(len(tables))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the answer as num_tables and then run this cell\n",
    "num_tables = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the table schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many columns in the crime table have TIMESTAMP data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by fetching the crime table. Then take a look at the table schema, and check the field type of each column. \n",
    "# How many times does 'TIMESTAMP' appear?\n",
    "\n",
    "# Construct a reference to the \"crime\" table\n",
    "table_ref = dataset_ref.table(\"crime\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Print information on all the columns in the \"crime\" table in the \"chicago_crime\" dataset\n",
    "print(table.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timestamp_fields = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a crime map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to create a map with a dot at the location of each crime, what are the names of the two fields you likely need to pull out of the crime table to plot the crimes on a map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Look at the table schema. There are a couple options, but two of the fields are things commonly used to plot on maps. \n",
    "# Both are 'FLOAT' types. Use quotes around the field names in your answer.\n",
    "\n",
    "fields_for_plotting = ['latitude', 'longitude'] # Put your answers here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
